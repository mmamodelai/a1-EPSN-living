{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXnHFUzNcFhsqPCg0o2g1v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"l3PsEFWGcktP"},"outputs":[],"source":["#!/usr/bin/env python3\n","\n","import requests\n","import pandas as pd\n","from pathlib import Path\n","from concurrent.futures import ThreadPoolExecutor\n","from tqdm import tqdm\n","import os\n","from bs4 import BeautifulSoup\n","import time\n","import logging\n","from typing import Dict, List, Optional\n","import json\n","from requests.adapters import HTTPAdapter\n","from requests.packages.urllib3.util.retry import Retry\n","import random\n","from datetime import datetime\n","\n","class ESPNFighterScraper:\n","    USER_AGENTS = [\n","        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n","        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',\n","        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',\n","        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59',\n","        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","    ]\n","\n","    def _init_(self, output_dir: str = 'fighter_profiles', max_workers: int = 3,\n","                 rate_limit: float = 2.0, max_retries: int = 5):\n","        self.output_dir = Path(output_dir)\n","        self.output_dir.mkdir(parents=True, exist_ok=True)\n","        self.max_workers = max_workers\n","        self.rate_limit = rate_limit\n","        self.max_retries = max_retries\n","        self.session = self._create_session()\n","\n","        self.success_count = 0\n","        self.failure_count = 0\n","        self.last_request_time = 0\n","        self.request_count = 0\n","        self.requests_this_minute = 0\n","        self.minute_start = datetime.now()\n","\n","    def _create_session(self) -> requests.Session:\n","        session = requests.Session()\n","\n","        retry_strategy = Retry(\n","            total=3,\n","            backoff_factor=2,\n","            status_forcelist=[429, 500, 502, 503, 504],\n","            allowed_methods=[\"GET\"]\n","        )\n","\n","        adapter = HTTPAdapter(max_retries=retry_strategy)\n","        session.mount(\"https://\", adapter)\n","        session.mount(\"http://\", adapter)\n","\n","        session.headers.update({\n","            'User-Agent': random.choice(self.USER_AGENTS),\n","            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8',\n","            'Accept-Language': 'en-US,en;q=0.5',\n","            'Accept-Encoding': 'gzip, deflate, br',\n","            'DNT': '1',\n","            'Connection': 'keep-alive',\n","            'Upgrade-Insecure-Requests': '1'\n","        })\n","\n","        return session\n","\n","    def _rotate_user_agent(self):\n","        self.session.headers['User-Agent'] = random.choice(self.USER_AGENTS)\n","\n","    def _rate_limit_wait(self):\n","        current_time = datetime.now()\n","\n","        if (current_time - self.minute_start).total_seconds() >= 60:\n","            self.requests_this_minute = 0\n","            self.minute_start = current_time\n","\n","        if self.requests_this_minute >= 25:\n","            sleep_time = 60 - (current_time - self.minute_start).total_seconds()\n","            if sleep_time > 0:\n","                time.sleep(sleep_time)\n","                self.minute_start = datetime.now()\n","                self.requests_this_minute = 0\n","\n","        time_since_last = time.time() - self.last_request_time\n","        if time_since_last < self.rate_limit:\n","            time.sleep(self.rate_limit - time_since_last)\n","\n","        self.last_request_time = time.time()\n","        self.requests_this_minute += 1\n","\n","    def _make_request(self, url: str, retries: int = 0) -> requests.Response:\n","        try:\n","            self._rate_limit_wait()\n","            self._rotate_user_agent()\n","\n","            response = self.session.get(url, timeout=10)\n","            response.raise_for_status()\n","            return response\n","\n","        except requests.exceptions.HTTPError as e:\n","            if e.response.status_code == 403 and retries < self.max_retries:\n","                wait_time = (2 ** retries) + random.uniform(0, 1)\n","                logging.warning(f\"403 error, waiting {wait_time:.2f} seconds before retry {retries + 1}\")\n","                time.sleep(wait_time)\n","                return self._make_request(url, retries + 1)\n","            raise\n","\n","    def fetch_fighter_data(self, fighter_name: str) -> Optional[Dict]:\n","        try:\n","            # Step 1: Search for fighter\n","            encoded_name = requests.utils.quote(fighter_name)\n","            search_url = f\"https://site.web.api.espn.com/apis/search/v2?region=us&lang=en&limit=10&page=1&query={encoded_name}\"\n","\n","            search_response = self._make_request(search_url)\n","            data_json = search_response.json()\n","\n","            # Find player data\n","            player_json_data = None\n","            if \"results\" in data_json:\n","                for result in data_json[\"results\"]:\n","                    if result.get(\"type\") == \"player\":\n","                        contents = result.get(\"contents\", [])\n","                        if isinstance(contents, list):\n","                            for content in contents:\n","                                if content.get(\"sport\") == \"mma\":\n","                                    player_json_data = content\n","                                    break\n","                    if player_json_data:\n","                        break\n","\n","            if not player_json_data:\n","                logging.warning(f\"No MMA fighter found for {fighter_name}\")\n","                self.failure_count += 1\n","                return None\n","\n","            # Step 2: Get fighter stats page\n","            profile_url = player_json_data[\"link\"][\"web\"]\n","            stats_url = profile_url.replace(\"//id/\", \"/stats//id/\")\n","\n","            profile_response = self._make_request(stats_url)\n","\n","            # Save HTML content\n","            file_path = self.output_dir / f\"{fighter_name.replace(' ', '_')}.html\"\n","            with open(file_path, 'w', encoding='utf-8') as f:\n","                f.write(profile_response.text)\n","\n","            self.success_count += 1\n","            logging.info(f\"Successfully processed {fighter_name}\")\n","\n","            return {\n","                'name': fighter_name,\n","                'profile_url': profile_url,\n","                'stats_url': stats_url,\n","                'file_path': str(file_path)\n","            }\n","\n","        except Exception as e:\n","            self.failure_count += 1\n","            logging.error(f\"Error processing {fighter_name}: {str(e)}\")\n","            return None\n","\n","    def process_saved_profiles(self) -> Dict[str, pd.DataFrame]:\n","        section_data = {\n","            'striking': [],\n","            'Clinch': [],\n","            'Ground': []\n","        }\n","\n","        columns = {\n","            'striking': ['Date', 'Opponent', 'Event', 'Result', 'SDBL/A', 'SDHL/A', 'SDLL/A',\n","                        'TSL', 'TSA', 'SSL', 'SSA', 'TSL-TSA', 'KD', '%BODY', '%HEAD', '%LEG'],\n","            'Clinch': ['Date', 'Opponent', 'Event', 'Result', 'SCBL', 'SCBA', 'SCHL', 'SCHA',\n","                      'SCLL', 'SCLA', 'RV', 'SR', 'TDL', 'TDA', 'TDS', 'TK ACC'],\n","            'Ground': ['Date', 'Opponent', 'Event', 'Result', 'SGBL', 'SGBA', 'SGHL', 'SGHA',\n","                      'SGLL', 'SGLA', 'AD', 'ADHG', 'ADTB', 'ADTM', 'ADTS', 'SM']\n","        }\n","\n","        for file_path in self.output_dir.glob('*.html'):\n","            try:\n","                with open(file_path, 'r', encoding='utf-8') as f:\n","                    soup = BeautifulSoup(f.read(), 'lxml')\n","\n","                player_name_elem = soup.find('h1', class_='PlayerHeader__Name')\n","                player_name = player_name_elem.get_text(strip=True) if player_name_elem else 'Unknown Player'\n","\n","                for section in ['striking', 'Clinch', 'Ground']:\n","                    title_div = soup.find('div', string=section)\n","                    if title_div:\n","                        table = title_div.find_next('table')\n","                        if table:\n","                            rows = table.find_all('tr')[1:]  # Skip header\n","                            for row in rows:\n","                                cols = [td.get_text(strip=True) for td in row.find_all('td')]\n","                                if len(cols) >= len(columns[section]):\n","                                    data = {'Player': player_name}\n","                                    data.update(dict(zip(columns[section], cols)))\n","                                    section_data[section].append(data)\n","\n","            except Exception as e:\n","                logging.error(f\"Error processing file {file_path}: {str(e)}\")\n","\n","        # Convert to DataFrames if there's data\n","        result_dfs = {}\n","        for section, data in section_data.items():\n","            if data:  # Only create DataFrame if there's data\n","                result_dfs[section] = pd.DataFrame(data)\n","            else:\n","                logging.warning(f\"No data found for section: {section}\")\n","                result_dfs[section] = pd.DataFrame(columns=['Player'] + columns[section])\n","\n","        return result_dfs\n","\n","    def scrape_fighters(self, fighters: List[str]) -> Dict[str, pd.DataFrame]:\n","        logging.info(f\"Starting scrape for {len(fighters)} fighters\")\n","\n","        chunk_size = 50\n","        all_results = []\n","\n","        for i in range(0, len(fighters), chunk_size):\n","            chunk = fighters[i:i + chunk_size]\n","\n","            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n","                chunk_results = list(tqdm(\n","                    executor.map(self.fetch_fighter_data, chunk),\n","                    total=len(chunk),\n","                    desc=f\"Processing fighters {i+1}-{min(i+chunk_size, len(fighters))}\"\n","                ))\n","                all_results.extend(chunk_results)\n","\n","            if i + chunk_size < len(fighters):\n","                pause_time = random.uniform(5, 10)\n","                logging.info(f\"Pausing for {pause_time:.2f} seconds between chunks\")\n","                time.sleep(pause_time)\n","\n","        successful_fighters = [r for r in all_results if r is not None]\n","        logging.info(f\"Successfully processed {len(successful_fighters)} out of {len(fighters)} fighters\")\n","\n","        section_dfs = self.process_saved_profiles()\n","\n","        for section, df in section_dfs.items():\n","            output_path = f'{section.lower()}_data.csv'\n","            df.to_csv(output_path, index=False)\n","            logging.info(f\"Saved {section} data to {output_path}\")\n","\n","        return section_dfs\n","\n","\n","def main():\n","    logging.basicConfig(\n","        level=logging.INFO,\n","        format='%(asctime)s - %(levelname)s - %(message)s',\n","        handlers=[\n","            logging.FileHandler('scraper.log'),\n","            logging.StreamHandler()\n","        ]\n","    )\n","\n","    script_dir = Path(_file_).parent.absolute()\n","    fighters_csv_path = script_dir / 'fighters_name.csv'\n","\n","    try:\n","        fighters_df = pd.read_csv(fighters_csv_path)\n","        fighters = fighters_df[\"fighters\"].tolist()\n","\n","        logging.info(f\"Found {len(fighters)} fighters in {fighters_csv_path}\")\n","\n","        scraper = ESPNFighterScraper(\n","            output_dir=script_dir / 'fighter_profiles',\n","            max_workers=3,\n","            rate_limit=2.0\n","        )\n","\n","        results = scraper.scrape_fighters(fighters)\n","\n","        print(\"\\nScraping Summary:\")\n","        print(f\"Total Success Cases: {scraper.success_count}\")\n","        print(f\"Total Failure Cases: {scraper.failure_count}\")\n","\n","        for section, df in results.items():\n","            print(f\"\\nSection: {section}\")\n","            if not df.empty:\n","                print(df.head())\n","            else:\n","                print(\"No data available\")\n","\n","    except FileNotFoundError:\n","        logging.error(f\"Could not find fighters_name.csv in {script_dir}\")\n","        print(f\"Error: fighters_name.csv not found in {script_dir}\")\n","        print(\"Please ensure fighters_name.csv is in the same directory as this script.\")\n","        return\n","    except Exception as e:\n","        logging.error(f\"An error occurred: {str(e)}\")\n","        print(f\"An error occurred: {str(e)}\")\n","        return\n","\n","\n","if _name_ == \"_main_\":\n","    main()"]}]}